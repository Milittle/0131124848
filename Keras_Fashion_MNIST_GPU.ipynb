{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Fashion MNIST - GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Milittle/0131124848/blob/master/Keras_Fashion_MNIST_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xdHrJctkrH9U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%capture\n",
        "!pip install watermark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "conjYMPerLfW",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%load_ext watermark\n",
        "%watermark -p tensorflow,numpy -m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5P9ue5OK7jKG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(Adapted from https://github.com/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Ot79jiI7GiHR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST with Keras and GPU\n",
        "\n",
        "First, let's grab our dataset using `tf.keras.datasets`."
      ]
    },
    {
      "metadata": {
        "id": "Zo-Yk6LFGfSf",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIBg5cUtso-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Value distribution of X:"
      ]
    },
    {
      "metadata": {
        "id": "4OMHWt6osCz3",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "pd.Series(x_train.reshape(-1)).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1C-WcdnNsyFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Value distribution of Y:\n"
      ]
    },
    {
      "metadata": {
        "id": "MCOsHdxEsjQD",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "pd.Series(y_train.reshape(-1)).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lx_VvBFNxHsr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a validation set"
      ]
    },
    {
      "metadata": {
        "id": "flkZMTP7xGvc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "sss = StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=1/6)\n",
        "train_index, valid_index = next(sss.split(x_train, y_train))\n",
        "x_valid, y_valid = x_train[valid_index], y_train[valid_index]\n",
        "x_train, y_train = x_train[train_index], y_train[train_index]\n",
        "print(x_train.shape, x_valid.shape, x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hgc2FZKVMx15",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining our model\n",
        "\n",
        "We will use a standard conv-net for this example.  We have 3 layers with drop-out and batch normalization between each layer."
      ]
    },
    {
      "metadata": {
        "id": "W7gMbs70GxA7",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('elu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLeZATVaNAnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training on the GPU\n",
        "\n",
        "Here we demonstrate that we can use a generator function and `fit_generator` to train the model.  You can also pass in `x_train` and `y_train` to `tpu_model.fit()` instead."
      ]
    },
    {
      "metadata": {
        "id": "pWEYmd_hIWg8",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1Zf7QtDvJAU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%time\n",
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "    yield x_train[offset:offset+batch_size], y_train[offset:offset + batch_size]\n",
        "    \n",
        "\n",
        "model.fit_generator(\n",
        "    train_gen(512),\n",
        "    epochs=15,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=(x_valid, y_valid)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESL6ltQTMm05",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Checking our results (inference)\n"
      ]
    },
    {
      "metadata": {
        "id": "SaYPv_aKId2d",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
        "\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_predictions(images, predictions, true_labels):\n",
        "  n = images.shape[0]\n",
        "  nc = int(np.ceil(n / 4))\n",
        "  fig = pyplot.figure(figsize=(4,3))\n",
        "  # axes = fig.add_subplot(nc, 4)\n",
        "  f, axes = pyplot.subplots(nc, 4)\n",
        "  f.tight_layout()\n",
        "  for i in range(nc * 4):\n",
        "    y = i // 4\n",
        "    x = i % 4\n",
        "    axes[x, y].axis('off')\n",
        "    \n",
        "    label = LABEL_NAMES[np.argmax(predictions[i])]\n",
        "    confidence = np.max(predictions[i])\n",
        "    if i > n:\n",
        "      continue\n",
        "    axes[x, y].imshow(images[i])\n",
        "    pred_label = np.argmax(predictions[i])\n",
        "    axes[x, y].set_title(\"{} ({})\\n {:.3f}\".format(\n",
        "      LABEL_NAMES[pred_label], \n",
        "      LABEL_NAMES[true_labels[i]],\n",
        "      confidence\n",
        "    ), color=(\"green\" if true_labels[i] == pred_label else \"red\"))\n",
        "  pyplot.gcf().set_size_inches(8, 8)  \n",
        "\n",
        "plot_predictions(\n",
        "    np.squeeze(x_test[:16]), \n",
        "    model.predict(x_test[:16]),\n",
        "    y_test[:16]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0m_OqgFzAK6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%time\n",
        "# Evaluate the model on valid set\n",
        "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Valid accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VgNcgjnMt6ER",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%time\n",
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJAaFlQYNhoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Not bad!"
      ]
    }
  ]
}